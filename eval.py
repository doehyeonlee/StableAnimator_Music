#!/usr/bin/env python3
# evaluate_fluency.py

"""
Temporal Fluency Metric for Video Generation Evaluation

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì„¸ê·¸ë©˜í…Œì´ì…˜ ê¸°ë°˜ ì‹œê°„ì  ìœ ì°½ì„±(Temporal Fluency)ì„ ì¸¡ì •í•©ë‹ˆë‹¤.

ìˆ˜ì‹:
    c_t = |B_t âŠ• B_{t+1}| / |B_t âˆª B_{t+1}|  (í”„ë ˆì„ ë³€í™” ë¹„ìœ¨)
    Î¼_V = mean(c_t)  (í‰ê·  ë³€í™”ëŸ‰)
    ÏƒÂ²_V = var(c_t)  (ë³€í™”ëŸ‰ ë¶„ì‚°)
    F_V = 1 / (1 + Î¼_V + ÏƒÂ²_V)  (ìœ ì°½ì„± ì ìˆ˜)

ì ìˆ˜ í•´ì„:
    - 0.90~1.00: ìµœìƒ (ì‹¤ì œ ë¹„ë””ì˜¤ ìˆ˜ì¤€)
    - 0.80~0.90: ìš°ìˆ˜ (ìì—°ìŠ¤ëŸ¬ì›€)
    - 0.70~0.80: ì–‘í˜¸ (ì•½ê°„ì˜ ëŠê¹€)
    - 0.60~0.70: ë³´í†µ (ëˆˆì— ë„ëŠ” ëŠê¹€)
    - < 0.60: ë¶ˆëŸ‰ (ì‹¬í•œ ëŠê¹€)

Author: [Your Name]
Date: 2025-01-28
"""

import numpy as np
import os
import glob
from pathlib import Path
import argparse
from tqdm import tqdm
import json
import pandas as pd
from typing import List, Dict, Tuple, Optional
import warnings

warnings.filterwarnings('ignore')


class FluencyEvaluator:
    """ë¹„ë””ì˜¤ ìœ ì°½ì„± í‰ê°€ í´ë˜ìŠ¤"""
    
    def __init__(self, fps: int = 30, window_seconds: int = 5):
        """
        Args:
            fps: í”„ë ˆì„ë ˆì´íŠ¸ (frames per second)
            window_seconds: í‰ê°€ ìœˆë„ìš° í¬ê¸° (ì´ˆ)
        """
        self.fps = fps
        self.window_seconds = window_seconds
        self.window_frames = fps * window_seconds
    
    @staticmethod
    def load_segmentation(npy_path: str) -> Optional[np.ndarray]:
        """
        ì„¸ê·¸ë©˜í…Œì´ì…˜ .npy íŒŒì¼ ë¡œë“œ
        
        Args:
            npy_path: .npy íŒŒì¼ ê²½ë¡œ
            
        Returns:
            body_mask: ì‹ ì²´ ì˜ì—­ ì´ì§„ ë§ˆìŠ¤í¬ (H, W) ë˜ëŠ” None
        """
        try:
            seg = np.load(npy_path)
            # ë°°ê²½(0) ì œì™¸, ì‹ ì²´ ë¶€ìœ„ë§Œ (>0)
            body_mask = seg > 0
            return body_mask
        except Exception as e:
            print(f"Error loading {npy_path}: {e}")
            return None
    
    @staticmethod
    def compute_frame_change(mask1: np.ndarray, mask2: np.ndarray) -> Optional[float]:
        """
        ë‘ í”„ë ˆì„ ê°„ ì‹ ì²´ í”½ì…€ ë³€í™” ë¹„ìœ¨ ê³„ì‚°
        
        ìˆ˜ì‹: c_t = |B_t âŠ• B_{t+1}| / |B_t âˆª B_{t+1}|
        
        Args:
            mask1: í”„ë ˆì„ tì˜ ì‹ ì²´ ë§ˆìŠ¤í¬
            mask2: í”„ë ˆì„ t+1ì˜ ì‹ ì²´ ë§ˆìŠ¤í¬
            
        Returns:
            change_ratio: ë³€í™” ë¹„ìœ¨ [0, 1]
        """
        if mask1 is None or mask2 is None:
            return None
        
        # XOR ì—°ì‚°: ë³€í™”ëœ í”½ì…€ (ëŒ€ì¹­ ì°¨ì§‘í•©)
        changed_pixels = np.logical_xor(mask1, mask2)
        
        # Union: ì „ì²´ ì‹ ì²´ í”½ì…€
        total_body_pixels = np.logical_or(mask1, mask2).sum()
        
        if total_body_pixels == 0:
            return 0.0
        
        change_ratio = changed_pixels.sum() / total_body_pixels
        return float(change_ratio)
    
    def compute_temporal_fluency(
        self, 
        seg_files: List[str]
    ) -> Tuple[List[float], List[Dict], float, float, float]:
        """
        ì‹œê°„ì  ìœ ì°½ì„± ê³„ì‚°
        
        Args:
            seg_files: ì •ë ¬ëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            frame_changes: í”„ë ˆì„ë³„ ë³€í™”ëŸ‰ [c_1, c_2, ..., c_{N-1}]
            window_fluency: ìœˆë„ìš°ë³„ ìœ ì°½ì„± ì •ë³´
            overall_fluency: ì „ì²´ ìœ ì°½ì„± ì ìˆ˜ F_V
            avg_change: í‰ê·  ë³€í™”ëŸ‰ Î¼_V
            variance: ë³€í™”ëŸ‰ ë¶„ì‚° ÏƒÂ²_V
        """
        # 1. í”„ë ˆì„ë³„ ë³€í™”ëŸ‰ ê³„ì‚°
        frame_changes = []
        prev_mask = None
        
        print("í”„ë ˆì„ë³„ ë³€í™”ëŸ‰ ê³„ì‚° ì¤‘...")
        for seg_file in tqdm(seg_files, desc="Processing frames"):
            curr_mask = self.load_segmentation(seg_file)
            
            if prev_mask is not None and curr_mask is not None:
                change = self.compute_frame_change(prev_mask, curr_mask)
                if change is not None:
                    frame_changes.append(change)
            
            prev_mask = curr_mask
        
        if len(frame_changes) == 0:
            print("âš ï¸ ìœ íš¨í•œ í”„ë ˆì„ ë³€í™”ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return [], [], 0.0, 0.0, 0.0
        
        # 2. ì „ì²´ í†µê³„ ê³„ì‚°
        avg_change = float(np.mean(frame_changes))
        variance = float(np.var(frame_changes))
        overall_fluency = 1.0 / (1.0 + avg_change + variance)
        
        # 3. ìœˆë„ìš°ë³„ ìœ ì°½ì„± ê³„ì‚°
        window_fluency = []
        
        print(f"\n{self.window_seconds}ì´ˆ ìœˆë„ìš°ë³„ ìœ ì°½ì„± ê³„ì‚° ì¤‘...")
        for i in range(0, len(frame_changes), self.window_frames):
            window = frame_changes[i:i+self.window_frames]
            
            if len(window) > 0:
                w_avg = float(np.mean(window))
                w_var = float(np.var(window))
                w_fluency = 1.0 / (1.0 + w_avg + w_var)
                
                window_fluency.append({
                    'window_id': len(window_fluency) + 1,
                    'start_frame': i,
                    'end_frame': min(i + self.window_frames, len(frame_changes)),
                    'num_frames': len(window),
                    'avg_change': w_avg,
                    'variance': w_var,
                    'fluency_score': w_fluency
                })
        
        return frame_changes, window_fluency, overall_fluency, avg_change, variance
    
    def evaluate_folder(
        self, 
        seg_folder: str, 
        output_dir: Optional[str] = None,
        verbose: bool = True
    ) -> Optional[Dict]:
        """
        í´ë” ë‚´ ëª¨ë“  ì„¸ê·¸ë©˜í…Œì´ì…˜ í‰ê°€
        
        Args:
            seg_folder: ì„¸ê·¸ë©˜í…Œì´ì…˜ í´ë” ê²½ë¡œ
            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ ì €ì¥ ì•ˆ í•¨)
            verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
            
        Returns:
            results: í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # .npy íŒŒì¼ ì°¾ê¸° ë° ì •ë ¬
        seg_files = sorted(glob.glob(os.path.join(seg_folder, '*_seg.npy')))
        
        if len(seg_files) == 0:
            print(f"âŒ {seg_folder}ì—ì„œ ì„¸ê·¸ë©˜í…Œì´ì…˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        if verbose:
            print(f"\n{'='*70}")
            print(f"ğŸ“ í´ë”: {seg_folder}")
            print(f"ğŸ“Š ì´ í”„ë ˆì„ ìˆ˜: {len(seg_files)}")
            print(f"ğŸ¬ FPS: {self.fps}")
            print(f"â±ï¸  ìœˆë„ìš°: {self.window_seconds}ì´ˆ")
            print('='*70)
        
        # ìœ ì°½ì„± ê³„ì‚°
        frame_changes, window_fluency, overall_fluency, avg_change, variance = \
            self.compute_temporal_fluency(seg_files)
        
        if len(frame_changes) == 0:
            return None
        
        # ê²°ê³¼ ì¶œë ¥
        if verbose:
            self._print_results(
                overall_fluency, avg_change, variance, 
                frame_changes, window_fluency
            )
        
        # ê²°ê³¼ ì €ì¥
        folder_name = Path(seg_folder).parent.parent.name
        # folder_name = Path(seg_folder).parent.name
        
        results = {
            'folder': seg_folder,
            'folder_name': folder_name,
            'total_frames': len(seg_files),
            'fps': self.fps,
            'window_seconds': self.window_seconds,
            'overall_fluency': overall_fluency,
            'avg_change': avg_change,
            'variance': variance,
            'min_change': float(np.min(frame_changes)),
            'max_change': float(np.max(frame_changes)),
            'median_change': float(np.median(frame_changes)),
            'std_change': float(np.std(frame_changes)),
            'frame_changes': frame_changes,
            'window_fluency': window_fluency,
            'grade': self._get_grade(overall_fluency)
        }
        
        if output_dir:
            self._save_results(results, output_dir, folder_name)
        
        return results
    
    def _print_results(
        self, 
        overall_fluency: float,
        avg_change: float, 
        variance: float,
        frame_changes: List[float], 
        window_fluency: List[Dict]
    ):
        """ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "="*70)
        print("ğŸ“ˆ í‰ê°€ ê²°ê³¼")
        print("="*70)
        print(f"ì „ì²´ ìœ ì°½ì„± ì ìˆ˜ (F_V): {overall_fluency:.4f}")
        print(f"í‰ê·  ë³€í™”ëŸ‰ (Î¼_V): {avg_change:.4f}")
        print(f"ë³€í™”ëŸ‰ ë¶„ì‚° (ÏƒÂ²_V): {variance:.4f}")
        print(f"ë³€í™”ëŸ‰ ë²”ìœ„: [{np.min(frame_changes):.4f}, {np.max(frame_changes):.4f}]")
        print(f"ë³€í™”ëŸ‰ ì¤‘ì•™ê°’: {np.median(frame_changes):.4f}")
        print(f"ë³€í™”ëŸ‰ í‘œì¤€í¸ì°¨: {np.std(frame_changes):.4f}")
        print(f"ë“±ê¸‰: {self._get_grade(overall_fluency)}")
        
        print(f"\n{self.window_seconds}ì´ˆ ìœˆë„ìš°ë³„ ìœ ì°½ì„±:")
        for w in window_fluency:
            print(f"  ìœˆë„ìš° {w['window_id']} "
                  f"(í”„ë ˆì„ {w['start_frame']}-{w['end_frame']}): "
                  f"F={w['fluency_score']:.4f}, "
                  f"Î¼={w['avg_change']:.4f}, "
                  f"ÏƒÂ²={w['variance']:.4f}")
    
    @staticmethod
    def _get_grade(fluency: float) -> str:
        """ìœ ì°½ì„± ì ìˆ˜ë¥¼ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜"""
        if fluency >= 0.90:
            return "Excellent"
        elif fluency >= 0.80:
            return "Good"
        elif fluency >= 0.70:
            return "Fair"
        elif fluency >= 0.60:
            return "Poor"
        else:
            return "Very Poor"
    
    def _save_results(self, results: Dict, output_dir: str, folder_name: str):
        """ê²°ê³¼ ì €ì¥"""
        os.makedirs(output_dir, exist_ok=True)
        
        # 1. JSON ì €ì¥ (ìƒì„¸ ì •ë³´)
        json_file = os.path.join(output_dir, f"{folder_name}_fluency.json")
        
        # frame_changesëŠ” ìš©ëŸ‰ì´ í¬ë¯€ë¡œ ë³„ë„ ì €ì¥ ì˜µì…˜
        json_results = results.copy()
        if len(results['frame_changes']) > 1000:
            # í”„ë ˆì„ì´ ë§ìœ¼ë©´ í†µê³„ë§Œ ì €ì¥
            json_results['frame_changes'] = {
                'note': 'Too many frames. Statistics only.',
                'count': len(results['frame_changes']),
                'sample_first_10': results['frame_changes'][:10],
                'sample_last_10': results['frame_changes'][-10:]
            }
        
        with open(json_file, 'w') as f:
            json.dump(json_results, f, indent=2)
        
        print(f"\nâœ… JSON ì €ì¥: {json_file}")
        
        # 2. CSV ì €ì¥/ì—…ë°ì´íŠ¸ (ìš”ì•½ ì •ë³´)
        csv_file = os.path.join(output_dir, "fluency_summary.csv")
        self._update_csv(csv_file, results)
        print(f"âœ… CSV ì—…ë°ì´íŠ¸: {csv_file}")
    
    @staticmethod
    def _update_csv(csv_file: str, results: Dict):
        """CSV íŒŒì¼ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ í–‰ ë®ì–´ì“°ê¸° ë˜ëŠ” ìƒˆ í–‰ ì¶”ê°€)"""
        folder_name = results['folder_name']
        
        new_row = {
            'Folder': folder_name,
            'Overall_Fluency': f"{results['overall_fluency']:.4f}",
            'Avg_Change': f"{results['avg_change']:.4f}",
            'Variance': f"{results['variance']:.4f}",
            'Min_Change': f"{results['min_change']:.4f}",
            'Max_Change': f"{results['max_change']:.4f}",
            'Median_Change': f"{results['median_change']:.4f}",
            'Std_Change': f"{results['std_change']:.4f}",
            'Frames': results['total_frames'],
            'FPS': results['fps'],
            'Window_Sec': results['window_seconds'],
            'Grade': results['grade']
        }
        
        # CSV íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if os.path.exists(csv_file):
            df = pd.read_csv(csv_file)
            
            # ê°™ì€ í´ë”ê°€ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
            if folder_name in df['Folder'].values:
                # ê¸°ì¡´ í–‰ ì—…ë°ì´íŠ¸
                for col, value in new_row.items():
                    if col in df.columns:
                        df.loc[df['Folder'] == folder_name, col] = value
                    else:
                        df[col] = None
                        df.loc[df['Folder'] == folder_name, col] = value
                print(f"   â„¹ï¸  ê¸°ì¡´ í–‰ ì—…ë°ì´íŠ¸: {folder_name}")
            else:
                # ìƒˆë¡œìš´ í–‰ ì¶”ê°€
                df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)
                print(f"   â• ìƒˆë¡œìš´ í–‰ ì¶”ê°€: {folder_name}")
        else:
            # ìƒˆ CSV íŒŒì¼ ìƒì„±
            df = pd.DataFrame([new_row])
            print(f"   ğŸ“„ ìƒˆ CSV íŒŒì¼ ìƒì„±")
        
        # CSV ì €ì¥
        df.to_csv(csv_file, index=False)
    
    def batch_evaluate(
        self, 
        parent_folder: str, 
        output_dir: Optional[str] = None,
        pattern: str = '*/images/sapiens_seg'
    ):
        """
        ì—¬ëŸ¬ í´ë” ì¼ê´„ í‰ê°€
        
        Args:
            parent_folder: ë¶€ëª¨ í´ë” ê²½ë¡œ
            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
            pattern: ì„¸ê·¸ë©˜í…Œì´ì…˜ í´ë” ê²€ìƒ‰ íŒ¨í„´
        """
        # sapiens_seg í´ë” ì°¾ê¸°
        seg_folders = glob.glob(os.path.join(parent_folder, pattern))
        
        if len(seg_folders) == 0:
            print(f"âŒ {parent_folder}ì—ì„œ '{pattern}' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\n{'â–ˆ'*70}")
        print(f"ğŸ” ë°œê²¬ëœ í´ë”: {len(seg_folders)}ê°œ")
        print('â–ˆ'*70)
        
        all_results = []
        failed = []
        
        for i, seg_folder in enumerate(seg_folders, 1):
            print(f"\n\n{'='*70}")
            print(f"[{i}/{len(seg_folders)}]")
            print('='*70)
            
            try:
                result = self.evaluate_folder(seg_folder, output_dir, verbose=True)
                if result:
                    all_results.append(result)
                else:
                    failed.append(seg_folder)
            except Exception as e:
                print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
                failed.append(seg_folder)
        
        # ì „ì²´ ìš”ì•½
        self._print_summary(all_results, failed)
    
    @staticmethod
    def _print_summary(all_results: List[Dict], failed: List[str]):
        """ì „ì²´ ìš”ì•½ ì¶œë ¥"""
        if not all_results:
            print("\nâš ï¸ í‰ê°€ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("\n\n" + "="*70)
        print("ğŸ“Š ì „ì²´ ìš”ì•½")
        print("="*70)
        
        fluency_scores = [r['overall_fluency'] for r in all_results]
        avg_changes = [r['avg_change'] for r in all_results]
        variances = [r['variance'] for r in all_results]
        
        print(f"ì´ í‰ê°€: {len(all_results)}ê°œ")
        print(f"ì‹¤íŒ¨: {len(failed)}ê°œ")
        print()
        
        print("ìœ ì°½ì„± ì ìˆ˜ (F_V):")
        print(f"  í‰ê· : {np.mean(fluency_scores):.4f}")
        print(f"  ì¤‘ì•™ê°’: {np.median(fluency_scores):.4f}")
        print(f"  í‘œì¤€í¸ì°¨: {np.std(fluency_scores):.4f}")
        print(f"  ë²”ìœ„: [{np.min(fluency_scores):.4f}, {np.max(fluency_scores):.4f}]")
        print()
        
        print("í‰ê·  ë³€í™”ëŸ‰ (Î¼_V):")
        print(f"  í‰ê· : {np.mean(avg_changes):.4f}")
        print(f"  ì¤‘ì•™ê°’: {np.median(avg_changes):.4f}")
        print()
        
        print("ë¶„ì‚° (ÏƒÂ²_V):")
        print(f"  í‰ê· : {np.mean(variances):.4f}")
        print(f"  ì¤‘ì•™ê°’: {np.median(variances):.4f}")
        print()
        
        # ë“±ê¸‰ë³„ ë¶„í¬
        grades = [r['grade'] for r in all_results]
        grade_counts = pd.Series(grades).value_counts()
        print("ë“±ê¸‰ ë¶„í¬:")
        for grade in ['Excellent', 'Good', 'Fair', 'Poor', 'Very Poor']:
            count = grade_counts.get(grade, 0)
            percentage = (count / len(all_results)) * 100
            print(f"  {grade}: {count}ê°œ ({percentage:.1f}%)")
        
        if failed:
            print(f"\nâš ï¸ ì‹¤íŒ¨í•œ í´ë” {len(failed)}ê°œ:")
            for folder in failed[:10]:
                print(f"  - {folder}")
            if len(failed) > 10:
                print(f"  ... ì™¸ {len(failed)-10}ê°œ")
        
        print("="*70)


def main():
    parser = argparse.ArgumentParser(
        description='Sapiens ì„¸ê·¸ë©˜í…Œì´ì…˜ ê¸°ë°˜ Temporal Fluency í‰ê°€',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # ë‹¨ì¼ í´ë” í‰ê°€
  python evaluate_fluency.py /path/to/sapiens_seg --output ./results
  
  # ì—¬ëŸ¬ í´ë” ì¼ê´„ í‰ê°€
  python evaluate_fluency.py /path/to/parent --batch --output ./results
  
  # FPSì™€ ìœˆë„ìš° í¬ê¸° ì§€ì •
  python evaluate_fluency.py /path/to/sapiens_seg --fps 60 --window 3
        """
    )
    
    parser.add_argument(
        'input', 
        help='ì„¸ê·¸ë©˜í…Œì´ì…˜ í´ë” ë˜ëŠ” ë¶€ëª¨ í´ë” ê²½ë¡œ'
    )
    parser.add_argument(
        '--fps', 
        type=int, 
        default=30, 
        help='í”„ë ˆì„ë ˆì´íŠ¸ (ê¸°ë³¸: 30)'
    )
    parser.add_argument(
        '--window', 
        type=int, 
        default=5, 
        help='í‰ê°€ ìœˆë„ìš° í¬ê¸° (ì´ˆ, ê¸°ë³¸: 5)'
    )
    parser.add_argument(
        '--output', 
        help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬'
    )
    parser.add_argument(
        '--batch', 
        action='store_true', 
        help='ì—¬ëŸ¬ í´ë” ì¼ê´„ ì²˜ë¦¬'
    )
    parser.add_argument(
        '--pattern',
        default='*/images/sapiens_seg',
        help='ë°°ì¹˜ ëª¨ë“œì—ì„œ í´ë” ê²€ìƒ‰ íŒ¨í„´ (ê¸°ë³¸: */images/sapiens_seg)'
    )
    parser.add_argument(
        '--quiet',
        action='store_true',
        help='ìµœì†Œ ì¶œë ¥ ëª¨ë“œ'
    )
    
    args = parser.parse_args()
    
    # Evaluator ìƒì„±
    evaluator = FluencyEvaluator(fps=args.fps, window_seconds=args.window)
    
    # í‰ê°€ ì‹¤í–‰
    if args.batch:
        evaluator.batch_evaluate(
            args.input, 
            args.output,
            pattern=args.pattern
        )
    else:
        evaluator.evaluate_folder(
            args.input, 
            args.output,
            verbose=not args.quiet
        )


if __name__ == '__main__':
    main()
